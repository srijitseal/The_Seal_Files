{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01fd2890-df8f-4f01-a0e5-e80a5e16d75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>1_1</th>\n",
       "      <th>10_19</th>\n",
       "      <th>10_20</th>\n",
       "      <th>100_277</th>\n",
       "      <th>100_278</th>\n",
       "      <th>104_291</th>\n",
       "      <th>105_355</th>\n",
       "      <th>105_369</th>\n",
       "      <th>105_361</th>\n",
       "      <th>...</th>\n",
       "      <th>Cells_Neighbors_FirstClosestObjectNumber_Adjacent</th>\n",
       "      <th>Cells_Neighbors_SecondClosestObjectNumber_5</th>\n",
       "      <th>Cells_Neighbors_SecondClosestObjectNumber_Adjacent</th>\n",
       "      <th>Cells_Parent_Nuclei</th>\n",
       "      <th>Cytoplasm_Number_Object_Number</th>\n",
       "      <th>Cytoplasm_Parent_Cells</th>\n",
       "      <th>Cytoplasm_Parent_Nuclei</th>\n",
       "      <th>Nuclei_Neighbors_FirstClosestObjectNumber_1</th>\n",
       "      <th>Nuclei_Neighbors_SecondClosestObjectNumber_1</th>\n",
       "      <th>Nuclei_Number_Object_Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCOC(=O)c1ccc(NC(=S)N2CCSC2c2ccc(OC)cc2)cc1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.765625</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>1.328125</td>\n",
       "      <td>1.328125</td>\n",
       "      <td>1.328125</td>\n",
       "      <td>1.328125</td>\n",
       "      <td>0.960938</td>\n",
       "      <td>1.320312</td>\n",
       "      <td>1.328125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O=C(CC1NC(=O)NC1=O)Nc1cccc2ccccc12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.078125</td>\n",
       "      <td>2.718750</td>\n",
       "      <td>2.718750</td>\n",
       "      <td>2.503906</td>\n",
       "      <td>2.503906</td>\n",
       "      <td>2.503906</td>\n",
       "      <td>2.503906</td>\n",
       "      <td>3.242188</td>\n",
       "      <td>2.578125</td>\n",
       "      <td>2.503906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC(Nc1nc(nc2ccccc12)N1CCCC1)c1ccccc1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.765625</td>\n",
       "      <td>-8.140625</td>\n",
       "      <td>-8.140625</td>\n",
       "      <td>-8.250000</td>\n",
       "      <td>-8.250000</td>\n",
       "      <td>-8.250000</td>\n",
       "      <td>-8.250000</td>\n",
       "      <td>-7.710938</td>\n",
       "      <td>-7.546875</td>\n",
       "      <td>-8.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCCC(Oc1ccc(Br)cc1)c1nc2c3cc(OC)c(OC)cc3nc(S)n2n1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.320312</td>\n",
       "      <td>-7.828125</td>\n",
       "      <td>-7.828125</td>\n",
       "      <td>-7.796875</td>\n",
       "      <td>-7.804688</td>\n",
       "      <td>-7.796875</td>\n",
       "      <td>-7.796875</td>\n",
       "      <td>-7.859375</td>\n",
       "      <td>-7.695312</td>\n",
       "      <td>-7.804688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC1=C(C(NC(=O)N1)c1ccc(F)cc1)C(=O)OCc1ccc2OCOc2c1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.953125</td>\n",
       "      <td>-10.390625</td>\n",
       "      <td>-10.390625</td>\n",
       "      <td>-10.960938</td>\n",
       "      <td>-10.960938</td>\n",
       "      <td>-10.960938</td>\n",
       "      <td>-10.960938</td>\n",
       "      <td>-11.406250</td>\n",
       "      <td>-10.781250</td>\n",
       "      <td>-10.960938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16165</th>\n",
       "      <td>COC(=O)[C@H]1[C@H](CO)[C@H]2Cn3c(=O)c(\\C=C\\C)c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.039062</td>\n",
       "      <td>-2.031250</td>\n",
       "      <td>-2.031250</td>\n",
       "      <td>-1.550781</td>\n",
       "      <td>-1.550781</td>\n",
       "      <td>-1.550781</td>\n",
       "      <td>-1.550781</td>\n",
       "      <td>-1.546875</td>\n",
       "      <td>-2.945312</td>\n",
       "      <td>-1.550781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16166</th>\n",
       "      <td>C\\C=C\\c1ccc2n(C[C@H]3[C@H](CO)[C@H](N(C)[C@@H]...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.851562</td>\n",
       "      <td>-0.359375</td>\n",
       "      <td>-0.359375</td>\n",
       "      <td>-0.835938</td>\n",
       "      <td>-0.835938</td>\n",
       "      <td>-0.835938</td>\n",
       "      <td>-0.835938</td>\n",
       "      <td>-1.328125</td>\n",
       "      <td>-0.804688</td>\n",
       "      <td>-0.835938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16167</th>\n",
       "      <td>C\\C=C\\c1ccc2n(C[C@@H]3[C@@H](CO)[C@@H](N(C)[C@...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.851562</td>\n",
       "      <td>-3.359375</td>\n",
       "      <td>-3.359375</td>\n",
       "      <td>-3.835938</td>\n",
       "      <td>-3.835938</td>\n",
       "      <td>-3.835938</td>\n",
       "      <td>-3.835938</td>\n",
       "      <td>-3.328125</td>\n",
       "      <td>-4.054688</td>\n",
       "      <td>-3.835938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16168</th>\n",
       "      <td>C\\C=C\\c1ccc2n(C[C@H]3[C@H](CO)[C@@H](C(=O)N[C@...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.039062</td>\n",
       "      <td>-2.460938</td>\n",
       "      <td>-2.460938</td>\n",
       "      <td>-3.300781</td>\n",
       "      <td>-3.300781</td>\n",
       "      <td>-3.300781</td>\n",
       "      <td>-3.300781</td>\n",
       "      <td>-3.382812</td>\n",
       "      <td>-2.937500</td>\n",
       "      <td>-3.300781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16169</th>\n",
       "      <td>COC(=O)[C@@H]1[C@@H](CO)[C@@H]2Cn3c(=O)c(\\C=C\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.210938</td>\n",
       "      <td>-3.312500</td>\n",
       "      <td>-3.312500</td>\n",
       "      <td>-3.308594</td>\n",
       "      <td>-3.308594</td>\n",
       "      <td>-3.308594</td>\n",
       "      <td>-3.308594</td>\n",
       "      <td>-3.804688</td>\n",
       "      <td>-2.789062</td>\n",
       "      <td>-3.308594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16170 rows Ã— 284 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  smiles  1_1  10_19  10_20  \\\n",
       "0            CCOC(=O)c1ccc(NC(=S)N2CCSC2c2ccc(OC)cc2)cc1  NaN    NaN    NaN   \n",
       "1                     O=C(CC1NC(=O)NC1=O)Nc1cccc2ccccc12  0.0    NaN    NaN   \n",
       "2                   CC(Nc1nc(nc2ccccc12)N1CCCC1)c1ccccc1  NaN    NaN    NaN   \n",
       "3      CCCC(Oc1ccc(Br)cc1)c1nc2c3cc(OC)c(OC)cc3nc(S)n2n1  NaN    NaN    NaN   \n",
       "4      CC1=C(C(NC(=O)N1)c1ccc(F)cc1)C(=O)OCc1ccc2OCOc2c1  NaN    NaN    NaN   \n",
       "...                                                  ...  ...    ...    ...   \n",
       "16165  COC(=O)[C@H]1[C@H](CO)[C@H]2Cn3c(=O)c(\\C=C\\C)c...  NaN    NaN    NaN   \n",
       "16166  C\\C=C\\c1ccc2n(C[C@H]3[C@H](CO)[C@H](N(C)[C@@H]...  NaN    NaN    NaN   \n",
       "16167  C\\C=C\\c1ccc2n(C[C@@H]3[C@@H](CO)[C@@H](N(C)[C@...  NaN    NaN    NaN   \n",
       "16168  C\\C=C\\c1ccc2n(C[C@H]3[C@H](CO)[C@@H](C(=O)N[C@...  NaN    NaN    NaN   \n",
       "16169  COC(=O)[C@@H]1[C@@H](CO)[C@@H]2Cn3c(=O)c(\\C=C\\...  NaN    NaN    NaN   \n",
       "\n",
       "       100_277  100_278  104_291  105_355  105_369  105_361  ...  \\\n",
       "0          NaN      NaN      NaN      NaN      NaN      NaN  ...   \n",
       "1          NaN      NaN      NaN      NaN      NaN      NaN  ...   \n",
       "2          NaN      NaN      NaN      NaN      NaN      NaN  ...   \n",
       "3          NaN      NaN      NaN      NaN      NaN      NaN  ...   \n",
       "4          NaN      NaN      NaN      NaN      NaN      NaN  ...   \n",
       "...        ...      ...      ...      ...      ...      ...  ...   \n",
       "16165      NaN      NaN      NaN      NaN      NaN      NaN  ...   \n",
       "16166      NaN      NaN      NaN      NaN      NaN      NaN  ...   \n",
       "16167      NaN      NaN      NaN      NaN      NaN      NaN  ...   \n",
       "16168      NaN      NaN      NaN      NaN      NaN      NaN  ...   \n",
       "16169      NaN      NaN      NaN      NaN      NaN      NaN  ...   \n",
       "\n",
       "       Cells_Neighbors_FirstClosestObjectNumber_Adjacent  \\\n",
       "0                                               1.765625   \n",
       "1                                               3.078125   \n",
       "2                                              -7.765625   \n",
       "3                                              -7.320312   \n",
       "4                                             -10.953125   \n",
       "...                                                  ...   \n",
       "16165                                          -2.039062   \n",
       "16166                                          -0.851562   \n",
       "16167                                          -3.851562   \n",
       "16168                                          -4.039062   \n",
       "16169                                          -3.210938   \n",
       "\n",
       "       Cells_Neighbors_SecondClosestObjectNumber_5  \\\n",
       "0                                         0.890625   \n",
       "1                                         2.718750   \n",
       "2                                        -8.140625   \n",
       "3                                        -7.828125   \n",
       "4                                       -10.390625   \n",
       "...                                            ...   \n",
       "16165                                    -2.031250   \n",
       "16166                                    -0.359375   \n",
       "16167                                    -3.359375   \n",
       "16168                                    -2.460938   \n",
       "16169                                    -3.312500   \n",
       "\n",
       "       Cells_Neighbors_SecondClosestObjectNumber_Adjacent  \\\n",
       "0                                               0.890625    \n",
       "1                                               2.718750    \n",
       "2                                              -8.140625    \n",
       "3                                              -7.828125    \n",
       "4                                             -10.390625    \n",
       "...                                                  ...    \n",
       "16165                                          -2.031250    \n",
       "16166                                          -0.359375    \n",
       "16167                                          -3.359375    \n",
       "16168                                          -2.460938    \n",
       "16169                                          -3.312500    \n",
       "\n",
       "       Cells_Parent_Nuclei  Cytoplasm_Number_Object_Number  \\\n",
       "0                 1.328125                        1.328125   \n",
       "1                 2.503906                        2.503906   \n",
       "2                -8.250000                       -8.250000   \n",
       "3                -7.796875                       -7.804688   \n",
       "4               -10.960938                      -10.960938   \n",
       "...                    ...                             ...   \n",
       "16165            -1.550781                       -1.550781   \n",
       "16166            -0.835938                       -0.835938   \n",
       "16167            -3.835938                       -3.835938   \n",
       "16168            -3.300781                       -3.300781   \n",
       "16169            -3.308594                       -3.308594   \n",
       "\n",
       "       Cytoplasm_Parent_Cells  Cytoplasm_Parent_Nuclei  \\\n",
       "0                    1.328125                 1.328125   \n",
       "1                    2.503906                 2.503906   \n",
       "2                   -8.250000                -8.250000   \n",
       "3                   -7.796875                -7.796875   \n",
       "4                  -10.960938               -10.960938   \n",
       "...                       ...                      ...   \n",
       "16165               -1.550781                -1.550781   \n",
       "16166               -0.835938                -0.835938   \n",
       "16167               -3.835938                -3.835938   \n",
       "16168               -3.300781                -3.300781   \n",
       "16169               -3.308594                -3.308594   \n",
       "\n",
       "       Nuclei_Neighbors_FirstClosestObjectNumber_1  \\\n",
       "0                                         0.960938   \n",
       "1                                         3.242188   \n",
       "2                                        -7.710938   \n",
       "3                                        -7.859375   \n",
       "4                                       -11.406250   \n",
       "...                                            ...   \n",
       "16165                                    -1.546875   \n",
       "16166                                    -1.328125   \n",
       "16167                                    -3.328125   \n",
       "16168                                    -3.382812   \n",
       "16169                                    -3.804688   \n",
       "\n",
       "       Nuclei_Neighbors_SecondClosestObjectNumber_1  \\\n",
       "0                                          1.320312   \n",
       "1                                          2.578125   \n",
       "2                                         -7.546875   \n",
       "3                                         -7.695312   \n",
       "4                                        -10.781250   \n",
       "...                                             ...   \n",
       "16165                                     -2.945312   \n",
       "16166                                     -0.804688   \n",
       "16167                                     -4.054688   \n",
       "16168                                     -2.937500   \n",
       "16169                                     -2.789062   \n",
       "\n",
       "       Nuclei_Number_Object_Number  \n",
       "0                         1.328125  \n",
       "1                         2.503906  \n",
       "2                        -8.250000  \n",
       "3                        -7.804688  \n",
       "4                       -10.960938  \n",
       "...                            ...  \n",
       "16165                    -1.550781  \n",
       "16166                    -0.835938  \n",
       "16167                    -3.835938  \n",
       "16168                    -3.300781  \n",
       "16169                    -3.308594  \n",
       "\n",
       "[16170 rows x 284 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"CP_count_PUMA.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b901cbf2-cc11-4664-a16d-89500d1ca31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assays_list = data.columns.to_list()[1:-13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7edff45-103f-4437-b191-e79e11c3d4f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(assays_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45fff938-c312-4505-9c36-58c440b2b9e7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:8 Physical GPUs, 8 Logical GPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:X_train is clean.\n",
      "INFO:root:y_train is clean.\n",
      "INFO:root:X_test is clean.\n",
      "INFO:root:y_test is clean.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "324/324 [==============================] - 6s 7ms/step - loss: 0.0016 - masked_auc: 0.5389 - val_loss: 4.7066e-04 - val_masked_auc: 0.6598 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 5.1848e-04 - masked_auc: 0.6247 - val_loss: 4.2165e-04 - val_masked_auc: 0.7196 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.7564e-04 - masked_auc: 0.6703 - val_loss: 4.1930e-04 - val_masked_auc: 0.7208 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.6342e-04 - masked_auc: 0.6820 - val_loss: 4.1518e-04 - val_masked_auc: 0.7275 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.5471e-04 - masked_auc: 0.6932 - val_loss: 4.1469e-04 - val_masked_auc: 0.7289 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.5047e-04 - masked_auc: 0.6979 - val_loss: 4.1107e-04 - val_masked_auc: 0.7346 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.4589e-04 - masked_auc: 0.7035 - val_loss: 4.1130e-04 - val_masked_auc: 0.7353 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.4025e-04 - masked_auc: 0.7106 - val_loss: 4.0970e-04 - val_masked_auc: 0.7341 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.4073e-04 - masked_auc: 0.7098 - val_loss: 4.0755e-04 - val_masked_auc: 0.7380 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.3827e-04 - masked_auc: 0.7125 - val_loss: 4.0876e-04 - val_masked_auc: 0.7393 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.3483e-04 - masked_auc: 0.7184 - val_loss: 4.0789e-04 - val_masked_auc: 0.7380 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.3397e-04 - masked_auc: 0.7190 - val_loss: 4.0727e-04 - val_masked_auc: 0.7385 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.3262e-04 - masked_auc: 0.7206 - val_loss: 4.0652e-04 - val_masked_auc: 0.7430 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.3238e-04 - masked_auc: 0.7220 - val_loss: 4.0688e-04 - val_masked_auc: 0.7415 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.3177e-04 - masked_auc: 0.7219 - val_loss: 4.0596e-04 - val_masked_auc: 0.7429 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2985e-04 - masked_auc: 0.7250 - val_loss: 4.0630e-04 - val_masked_auc: 0.7403 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2984e-04 - masked_auc: 0.7253 - val_loss: 4.0532e-04 - val_masked_auc: 0.7436 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2794e-04 - masked_auc: 0.7279 - val_loss: 4.0544e-04 - val_masked_auc: 0.7434 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2729e-04 - masked_auc: 0.7302 - val_loss: 4.0520e-04 - val_masked_auc: 0.7438 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2811e-04 - masked_auc: 0.7273 - val_loss: 4.0509e-04 - val_masked_auc: 0.7438 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2762e-04 - masked_auc: 0.7276 - val_loss: 4.0578e-04 - val_masked_auc: 0.7421 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2722e-04 - masked_auc: 0.7303 - val_loss: 4.0514e-04 - val_masked_auc: 0.7453 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2558e-04 - masked_auc: 0.7314 - val_loss: 4.0473e-04 - val_masked_auc: 0.7446 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2557e-04 - masked_auc: 0.7307 - val_loss: 4.0497e-04 - val_masked_auc: 0.7451 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2502e-04 - masked_auc: 0.7324 - val_loss: 4.0552e-04 - val_masked_auc: 0.7436 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2410e-04 - masked_auc: 0.7358 - val_loss: 4.0522e-04 - val_masked_auc: 0.7450 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2421e-04 - masked_auc: 0.7342 - val_loss: 4.0483e-04 - val_masked_auc: 0.7442 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2281e-04 - masked_auc: 0.7371 - val_loss: 4.0424e-04 - val_masked_auc: 0.7465 - lr: 5.0000e-04\n",
      "Epoch 29/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2185e-04 - masked_auc: 0.7373 - val_loss: 4.0464e-04 - val_masked_auc: 0.7449 - lr: 5.0000e-04\n",
      "Epoch 30/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2275e-04 - masked_auc: 0.7360 - val_loss: 4.0467e-04 - val_masked_auc: 0.7453 - lr: 5.0000e-04\n",
      "Epoch 31/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2248e-04 - masked_auc: 0.7359 - val_loss: 4.0483e-04 - val_masked_auc: 0.7454 - lr: 5.0000e-04\n",
      "Epoch 32/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2150e-04 - masked_auc: 0.7385 - val_loss: 4.0423e-04 - val_masked_auc: 0.7481 - lr: 5.0000e-04\n",
      "Epoch 33/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2243e-04 - masked_auc: 0.7389 - val_loss: 4.0588e-04 - val_masked_auc: 0.7439 - lr: 5.0000e-04\n",
      "Epoch 34/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2178e-04 - masked_auc: 0.7390 - val_loss: 4.0497e-04 - val_masked_auc: 0.7448 - lr: 5.0000e-04\n",
      "Epoch 35/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2206e-04 - masked_auc: 0.7370 - val_loss: 4.0617e-04 - val_masked_auc: 0.7422 - lr: 5.0000e-04\n",
      "Epoch 36/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2079e-04 - masked_auc: 0.7396 - val_loss: 4.0533e-04 - val_masked_auc: 0.7449 - lr: 5.0000e-04\n",
      "Epoch 37/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2130e-04 - masked_auc: 0.7386 - val_loss: 4.0486e-04 - val_masked_auc: 0.7448 - lr: 5.0000e-04\n",
      "Epoch 38/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2030e-04 - masked_auc: 0.7431 - val_loss: 4.0488e-04 - val_masked_auc: 0.7446 - lr: 2.5000e-04\n",
      "Epoch 39/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2038e-04 - masked_auc: 0.7406 - val_loss: 4.0524e-04 - val_masked_auc: 0.7452 - lr: 2.5000e-04\n",
      "Epoch 40/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2056e-04 - masked_auc: 0.7414 - val_loss: 4.0489e-04 - val_masked_auc: 0.7454 - lr: 2.5000e-04\n",
      "Epoch 41/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1926e-04 - masked_auc: 0.7421 - val_loss: 4.0495e-04 - val_masked_auc: 0.7457 - lr: 2.5000e-04\n",
      "Epoch 42/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2012e-04 - masked_auc: 0.7422 - val_loss: 4.0529e-04 - val_masked_auc: 0.7453 - lr: 2.5000e-04\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 4.0168e-04 - masked_auc: 0.7512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Fold 0 - loss: 0.00040168085251934826\n",
      "INFO:root:Fold 0 - masked_auc: 0.7511682510375977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:X_train is clean.\n",
      "INFO:root:y_train is clean.\n",
      "INFO:root:X_test is clean.\n",
      "INFO:root:y_test is clean.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "324/324 [==============================] - 5s 7ms/step - loss: 0.0016 - masked_auc: 0.5383 - val_loss: 4.9553e-04 - val_masked_auc: 0.6432 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 5.1242e-04 - masked_auc: 0.6329 - val_loss: 4.4560e-04 - val_masked_auc: 0.6962 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.7189e-04 - masked_auc: 0.6741 - val_loss: 4.3141e-04 - val_masked_auc: 0.7269 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.5696e-04 - masked_auc: 0.6936 - val_loss: 4.2626e-04 - val_masked_auc: 0.7313 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.4745e-04 - masked_auc: 0.7035 - val_loss: 4.2485e-04 - val_masked_auc: 0.7340 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.4418e-04 - masked_auc: 0.7088 - val_loss: 4.2226e-04 - val_masked_auc: 0.7380 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.3886e-04 - masked_auc: 0.7136 - val_loss: 4.2409e-04 - val_masked_auc: 0.7345 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.3655e-04 - masked_auc: 0.7160 - val_loss: 4.2219e-04 - val_masked_auc: 0.7380 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.3494e-04 - masked_auc: 0.7195 - val_loss: 4.2326e-04 - val_masked_auc: 0.7342 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.3140e-04 - masked_auc: 0.7237 - val_loss: 4.2072e-04 - val_masked_auc: 0.7386 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.3011e-04 - masked_auc: 0.7246 - val_loss: 4.2026e-04 - val_masked_auc: 0.7395 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2933e-04 - masked_auc: 0.7250 - val_loss: 4.1947e-04 - val_masked_auc: 0.7416 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2802e-04 - masked_auc: 0.7287 - val_loss: 4.1896e-04 - val_masked_auc: 0.7422 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2750e-04 - masked_auc: 0.7290 - val_loss: 4.1927e-04 - val_masked_auc: 0.7419 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2598e-04 - masked_auc: 0.7315 - val_loss: 4.1985e-04 - val_masked_auc: 0.7415 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2683e-04 - masked_auc: 0.7283 - val_loss: 4.1919e-04 - val_masked_auc: 0.7421 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2554e-04 - masked_auc: 0.7316 - val_loss: 4.1916e-04 - val_masked_auc: 0.7438 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2383e-04 - masked_auc: 0.7348 - val_loss: 4.1852e-04 - val_masked_auc: 0.7414 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2548e-04 - masked_auc: 0.7336 - val_loss: 4.1949e-04 - val_masked_auc: 0.7401 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2172e-04 - masked_auc: 0.7369 - val_loss: 4.1801e-04 - val_masked_auc: 0.7435 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2232e-04 - masked_auc: 0.7359 - val_loss: 4.1820e-04 - val_masked_auc: 0.7419 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2382e-04 - masked_auc: 0.7355 - val_loss: 4.1749e-04 - val_masked_auc: 0.7442 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2165e-04 - masked_auc: 0.7377 - val_loss: 4.1762e-04 - val_masked_auc: 0.7456 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2259e-04 - masked_auc: 0.7356 - val_loss: 4.1773e-04 - val_masked_auc: 0.7456 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2204e-04 - masked_auc: 0.7377 - val_loss: 4.1936e-04 - val_masked_auc: 0.7420 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2130e-04 - masked_auc: 0.7396 - val_loss: 4.1806e-04 - val_masked_auc: 0.7449 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2023e-04 - masked_auc: 0.7410 - val_loss: 4.1848e-04 - val_masked_auc: 0.7429 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2084e-04 - masked_auc: 0.7378 - val_loss: 4.1872e-04 - val_masked_auc: 0.7469 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1968e-04 - masked_auc: 0.7405 - val_loss: 4.1758e-04 - val_masked_auc: 0.7446 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2015e-04 - masked_auc: 0.7397 - val_loss: 4.1856e-04 - val_masked_auc: 0.7448 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1925e-04 - masked_auc: 0.7417 - val_loss: 4.1775e-04 - val_masked_auc: 0.7454 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1934e-04 - masked_auc: 0.7407 - val_loss: 4.1800e-04 - val_masked_auc: 0.7452 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1845e-04 - masked_auc: 0.7405 - val_loss: 4.1895e-04 - val_masked_auc: 0.7472 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1798e-04 - masked_auc: 0.7437 - val_loss: 4.1916e-04 - val_masked_auc: 0.7453 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1806e-04 - masked_auc: 0.7412 - val_loss: 4.1904e-04 - val_masked_auc: 0.7475 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1837e-04 - masked_auc: 0.7436 - val_loss: 4.1785e-04 - val_masked_auc: 0.7447 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1817e-04 - masked_auc: 0.7439 - val_loss: 4.1720e-04 - val_masked_auc: 0.7484 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1779e-04 - masked_auc: 0.7456 - val_loss: 4.1747e-04 - val_masked_auc: 0.7452 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1878e-04 - masked_auc: 0.7429 - val_loss: 4.1790e-04 - val_masked_auc: 0.7448 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1707e-04 - masked_auc: 0.7439 - val_loss: 4.1835e-04 - val_masked_auc: 0.7456 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1737e-04 - masked_auc: 0.7452 - val_loss: 4.1761e-04 - val_masked_auc: 0.7469 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1817e-04 - masked_auc: 0.7440 - val_loss: 4.1785e-04 - val_masked_auc: 0.7457 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1554e-04 - masked_auc: 0.7463 - val_loss: 4.1794e-04 - val_masked_auc: 0.7462 - lr: 5.0000e-04\n",
      "Epoch 44/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1527e-04 - masked_auc: 0.7489 - val_loss: 4.1792e-04 - val_masked_auc: 0.7483 - lr: 5.0000e-04\n",
      "Epoch 45/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1578e-04 - masked_auc: 0.7482 - val_loss: 4.1809e-04 - val_masked_auc: 0.7477 - lr: 5.0000e-04\n",
      "Epoch 46/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1505e-04 - masked_auc: 0.7478 - val_loss: 4.2082e-04 - val_masked_auc: 0.7478 - lr: 5.0000e-04\n",
      "Epoch 47/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1494e-04 - masked_auc: 0.7483 - val_loss: 4.1850e-04 - val_masked_auc: 0.7477 - lr: 5.0000e-04\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 4.0358e-04 - masked_auc: 0.7356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Fold 1 - loss: 0.0004035759484395385\n",
      "INFO:root:Fold 1 - masked_auc: 0.7356223464012146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:X_train is clean.\n",
      "INFO:root:y_train is clean.\n",
      "INFO:root:X_test is clean.\n",
      "INFO:root:y_test is clean.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "324/324 [==============================] - 5s 7ms/step - loss: 0.0016 - masked_auc: 0.5355 - val_loss: 4.6309e-04 - val_masked_auc: 0.6572 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 5.0876e-04 - masked_auc: 0.6320 - val_loss: 4.1417e-04 - val_masked_auc: 0.7121 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.6919e-04 - masked_auc: 0.6765 - val_loss: 4.0919e-04 - val_masked_auc: 0.7238 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.6051e-04 - masked_auc: 0.6914 - val_loss: 4.1283e-04 - val_masked_auc: 0.7180 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.4985e-04 - masked_auc: 0.7034 - val_loss: 4.0644e-04 - val_masked_auc: 0.7292 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.4516e-04 - masked_auc: 0.7092 - val_loss: 4.0727e-04 - val_masked_auc: 0.7255 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.3953e-04 - masked_auc: 0.7149 - val_loss: 4.0378e-04 - val_masked_auc: 0.7322 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.3650e-04 - masked_auc: 0.7169 - val_loss: 4.0446e-04 - val_masked_auc: 0.7310 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.3324e-04 - masked_auc: 0.7221 - val_loss: 4.0442e-04 - val_masked_auc: 0.7295 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.3205e-04 - masked_auc: 0.7235 - val_loss: 4.0235e-04 - val_masked_auc: 0.7326 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2941e-04 - masked_auc: 0.7270 - val_loss: 4.0279e-04 - val_masked_auc: 0.7336 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2953e-04 - masked_auc: 0.7258 - val_loss: 4.0240e-04 - val_masked_auc: 0.7313 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2862e-04 - masked_auc: 0.7277 - val_loss: 4.0133e-04 - val_masked_auc: 0.7346 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2638e-04 - masked_auc: 0.7319 - val_loss: 4.0123e-04 - val_masked_auc: 0.7324 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2727e-04 - masked_auc: 0.7296 - val_loss: 4.0170e-04 - val_masked_auc: 0.7332 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2580e-04 - masked_auc: 0.7315 - val_loss: 4.0125e-04 - val_masked_auc: 0.7336 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2519e-04 - masked_auc: 0.7334 - val_loss: 4.0106e-04 - val_masked_auc: 0.7332 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2386e-04 - masked_auc: 0.7361 - val_loss: 4.0153e-04 - val_masked_auc: 0.7349 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2343e-04 - masked_auc: 0.7355 - val_loss: 4.0113e-04 - val_masked_auc: 0.7352 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2303e-04 - masked_auc: 0.7372 - val_loss: 4.0162e-04 - val_masked_auc: 0.7328 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2287e-04 - masked_auc: 0.7361 - val_loss: 3.9989e-04 - val_masked_auc: 0.7370 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2279e-04 - masked_auc: 0.7357 - val_loss: 4.0248e-04 - val_masked_auc: 0.7352 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2079e-04 - masked_auc: 0.7401 - val_loss: 4.0068e-04 - val_masked_auc: 0.7358 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2118e-04 - masked_auc: 0.7390 - val_loss: 4.0135e-04 - val_masked_auc: 0.7364 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1981e-04 - masked_auc: 0.7402 - val_loss: 4.0276e-04 - val_masked_auc: 0.7345 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2058e-04 - masked_auc: 0.7393 - val_loss: 4.0157e-04 - val_masked_auc: 0.7337 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1916e-04 - masked_auc: 0.7415 - val_loss: 4.0023e-04 - val_masked_auc: 0.7363 - lr: 5.0000e-04\n",
      "Epoch 28/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1737e-04 - masked_auc: 0.7441 - val_loss: 4.0019e-04 - val_masked_auc: 0.7362 - lr: 5.0000e-04\n",
      "Epoch 29/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1697e-04 - masked_auc: 0.7445 - val_loss: 4.0135e-04 - val_masked_auc: 0.7358 - lr: 5.0000e-04\n",
      "Epoch 30/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1739e-04 - masked_auc: 0.7464 - val_loss: 4.0288e-04 - val_masked_auc: 0.7359 - lr: 5.0000e-04\n",
      "Epoch 31/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1695e-04 - masked_auc: 0.7443 - val_loss: 4.0182e-04 - val_masked_auc: 0.7370 - lr: 5.0000e-04\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 4.1718e-04 - masked_auc: 0.7351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Fold 2 - loss: 0.00041717931162565947\n",
      "INFO:root:Fold 2 - masked_auc: 0.7351248860359192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:X_train is clean.\n",
      "INFO:root:y_train is clean.\n",
      "INFO:root:X_test is clean.\n",
      "INFO:root:y_test is clean.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "324/324 [==============================] - 5s 7ms/step - loss: 0.0017 - masked_auc: 0.5319 - val_loss: 4.8590e-04 - val_masked_auc: 0.6614 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 5.1289e-04 - masked_auc: 0.6307 - val_loss: 4.2366e-04 - val_masked_auc: 0.7116 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.6979e-04 - masked_auc: 0.6785 - val_loss: 4.1709e-04 - val_masked_auc: 0.7286 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.5598e-04 - masked_auc: 0.6951 - val_loss: 4.1813e-04 - val_masked_auc: 0.7246 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.5067e-04 - masked_auc: 0.6986 - val_loss: 4.1236e-04 - val_masked_auc: 0.7384 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.4545e-04 - masked_auc: 0.7048 - val_loss: 4.1119e-04 - val_masked_auc: 0.7384 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.3886e-04 - masked_auc: 0.7130 - val_loss: 4.1100e-04 - val_masked_auc: 0.7362 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.3601e-04 - masked_auc: 0.7174 - val_loss: 4.0918e-04 - val_masked_auc: 0.7397 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.3318e-04 - masked_auc: 0.7222 - val_loss: 4.1155e-04 - val_masked_auc: 0.7366 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.3176e-04 - masked_auc: 0.7212 - val_loss: 4.0932e-04 - val_masked_auc: 0.7408 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.3026e-04 - masked_auc: 0.7257 - val_loss: 4.0979e-04 - val_masked_auc: 0.7407 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2891e-04 - masked_auc: 0.7242 - val_loss: 4.0960e-04 - val_masked_auc: 0.7423 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2803e-04 - masked_auc: 0.7271 - val_loss: 4.0910e-04 - val_masked_auc: 0.7421 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2549e-04 - masked_auc: 0.7294 - val_loss: 4.0825e-04 - val_masked_auc: 0.7429 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2658e-04 - masked_auc: 0.7285 - val_loss: 4.0828e-04 - val_masked_auc: 0.7410 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2446e-04 - masked_auc: 0.7309 - val_loss: 4.0995e-04 - val_masked_auc: 0.7377 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2526e-04 - masked_auc: 0.7311 - val_loss: 4.0878e-04 - val_masked_auc: 0.7409 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2389e-04 - masked_auc: 0.7326 - val_loss: 4.0706e-04 - val_masked_auc: 0.7432 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2383e-04 - masked_auc: 0.7316 - val_loss: 4.0871e-04 - val_masked_auc: 0.7398 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2111e-04 - masked_auc: 0.7368 - val_loss: 4.0931e-04 - val_masked_auc: 0.7394 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2260e-04 - masked_auc: 0.7336 - val_loss: 4.0805e-04 - val_masked_auc: 0.7417 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2177e-04 - masked_auc: 0.7354 - val_loss: 4.0720e-04 - val_masked_auc: 0.7429 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.2210e-04 - masked_auc: 0.7356 - val_loss: 4.0893e-04 - val_masked_auc: 0.7402 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1955e-04 - masked_auc: 0.7399 - val_loss: 4.0662e-04 - val_masked_auc: 0.7460 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1905e-04 - masked_auc: 0.7412 - val_loss: 4.0688e-04 - val_masked_auc: 0.7441 - lr: 5.0000e-04\n",
      "Epoch 26/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1983e-04 - masked_auc: 0.7395 - val_loss: 4.0649e-04 - val_masked_auc: 0.7456 - lr: 5.0000e-04\n",
      "Epoch 27/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1927e-04 - masked_auc: 0.7406 - val_loss: 4.0685e-04 - val_masked_auc: 0.7434 - lr: 5.0000e-04\n",
      "Epoch 28/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1979e-04 - masked_auc: 0.7404 - val_loss: 4.0674e-04 - val_masked_auc: 0.7451 - lr: 5.0000e-04\n",
      "Epoch 29/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1864e-04 - masked_auc: 0.7414 - val_loss: 4.0618e-04 - val_masked_auc: 0.7448 - lr: 5.0000e-04\n",
      "Epoch 30/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1795e-04 - masked_auc: 0.7417 - val_loss: 4.0624e-04 - val_masked_auc: 0.7458 - lr: 2.5000e-04\n",
      "Epoch 31/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1788e-04 - masked_auc: 0.7432 - val_loss: 4.0636e-04 - val_masked_auc: 0.7462 - lr: 2.5000e-04\n",
      "Epoch 32/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1740e-04 - masked_auc: 0.7460 - val_loss: 4.0637e-04 - val_masked_auc: 0.7454 - lr: 2.5000e-04\n",
      "Epoch 33/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1646e-04 - masked_auc: 0.7447 - val_loss: 4.0630e-04 - val_masked_auc: 0.7461 - lr: 2.5000e-04\n",
      "Epoch 34/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1697e-04 - masked_auc: 0.7450 - val_loss: 4.0623e-04 - val_masked_auc: 0.7460 - lr: 2.5000e-04\n",
      "Epoch 35/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1665e-04 - masked_auc: 0.7445 - val_loss: 4.0655e-04 - val_masked_auc: 0.7450 - lr: 2.5000e-04\n",
      "Epoch 36/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1577e-04 - masked_auc: 0.7463 - val_loss: 4.0654e-04 - val_masked_auc: 0.7456 - lr: 2.5000e-04\n",
      "Epoch 37/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1675e-04 - masked_auc: 0.7451 - val_loss: 4.0652e-04 - val_masked_auc: 0.7455 - lr: 1.2500e-04\n",
      "Epoch 38/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1504e-04 - masked_auc: 0.7483 - val_loss: 4.0672e-04 - val_masked_auc: 0.7448 - lr: 1.2500e-04\n",
      "Epoch 39/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1628e-04 - masked_auc: 0.7461 - val_loss: 4.0669e-04 - val_masked_auc: 0.7450 - lr: 1.2500e-04\n",
      "Epoch 40/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1615e-04 - masked_auc: 0.7465 - val_loss: 4.0663e-04 - val_masked_auc: 0.7450 - lr: 1.2500e-04\n",
      "Epoch 41/100\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 4.1616e-04 - masked_auc: 0.7461 - val_loss: 4.0659e-04 - val_masked_auc: 0.7458 - lr: 1.2500e-04\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 4.1856e-04 - masked_auc: 0.7345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Fold 3 - loss: 0.0004185629077255726\n",
      "INFO:root:Fold 3 - masked_auc: 0.7344642877578735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:X_train is clean.\n",
      "INFO:root:y_train is clean.\n",
      "INFO:root:X_test is clean.\n",
      "INFO:root:y_test is clean.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "323/323 [==============================] - 5s 7ms/step - loss: 0.0017 - masked_auc: 0.5319 - val_loss: 4.7952e-04 - val_masked_auc: 0.6721 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 5.0597e-04 - masked_auc: 0.6287 - val_loss: 4.2121e-04 - val_masked_auc: 0.7294 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.6227e-04 - masked_auc: 0.6776 - val_loss: 4.1656e-04 - val_masked_auc: 0.7378 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.5298e-04 - masked_auc: 0.6922 - val_loss: 4.1777e-04 - val_masked_auc: 0.7344 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.4435e-04 - masked_auc: 0.7016 - val_loss: 4.1431e-04 - val_masked_auc: 0.7412 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.3890e-04 - masked_auc: 0.7077 - val_loss: 4.1454e-04 - val_masked_auc: 0.7394 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.3612e-04 - masked_auc: 0.7110 - val_loss: 4.1348e-04 - val_masked_auc: 0.7434 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.3401e-04 - masked_auc: 0.7146 - val_loss: 4.1491e-04 - val_masked_auc: 0.7394 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.3232e-04 - masked_auc: 0.7162 - val_loss: 4.1154e-04 - val_masked_auc: 0.7446 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.2858e-04 - masked_auc: 0.7216 - val_loss: 4.1256e-04 - val_masked_auc: 0.7434 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.2775e-04 - masked_auc: 0.7225 - val_loss: 4.1209e-04 - val_masked_auc: 0.7448 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.2666e-04 - masked_auc: 0.7229 - val_loss: 4.1390e-04 - val_masked_auc: 0.7405 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.2668e-04 - masked_auc: 0.7232 - val_loss: 4.1195e-04 - val_masked_auc: 0.7436 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.2661e-04 - masked_auc: 0.7237 - val_loss: 4.1345e-04 - val_masked_auc: 0.7407 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.2476e-04 - masked_auc: 0.7265 - val_loss: 4.1322e-04 - val_masked_auc: 0.7419 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.2357e-04 - masked_auc: 0.7280 - val_loss: 4.1255e-04 - val_masked_auc: 0.7428 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.2077e-04 - masked_auc: 0.7308 - val_loss: 4.1067e-04 - val_masked_auc: 0.7478 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.2177e-04 - masked_auc: 0.7313 - val_loss: 4.1122e-04 - val_masked_auc: 0.7452 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.2070e-04 - masked_auc: 0.7305 - val_loss: 4.0996e-04 - val_masked_auc: 0.7482 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.1825e-04 - masked_auc: 0.7375 - val_loss: 4.1032e-04 - val_masked_auc: 0.7464 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.2014e-04 - masked_auc: 0.7340 - val_loss: 4.1037e-04 - val_masked_auc: 0.7477 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.1928e-04 - masked_auc: 0.7340 - val_loss: 4.1066e-04 - val_masked_auc: 0.7450 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.1950e-04 - masked_auc: 0.7334 - val_loss: 4.0986e-04 - val_masked_auc: 0.7491 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.1976e-04 - masked_auc: 0.7344 - val_loss: 4.1001e-04 - val_masked_auc: 0.7482 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.1921e-04 - masked_auc: 0.7343 - val_loss: 4.1064e-04 - val_masked_auc: 0.7462 - lr: 5.0000e-04\n",
      "Epoch 26/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.1927e-04 - masked_auc: 0.7353 - val_loss: 4.0946e-04 - val_masked_auc: 0.7485 - lr: 5.0000e-04\n",
      "Epoch 27/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.1698e-04 - masked_auc: 0.7392 - val_loss: 4.0988e-04 - val_masked_auc: 0.7485 - lr: 5.0000e-04\n",
      "Epoch 28/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.1827e-04 - masked_auc: 0.7361 - val_loss: 4.1038e-04 - val_masked_auc: 0.7459 - lr: 5.0000e-04\n",
      "Epoch 29/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.1607e-04 - masked_auc: 0.7400 - val_loss: 4.1019e-04 - val_masked_auc: 0.7477 - lr: 2.5000e-04\n",
      "Epoch 30/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.1616e-04 - masked_auc: 0.7409 - val_loss: 4.0966e-04 - val_masked_auc: 0.7485 - lr: 2.5000e-04\n",
      "Epoch 31/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.1681e-04 - masked_auc: 0.7396 - val_loss: 4.0989e-04 - val_masked_auc: 0.7482 - lr: 2.5000e-04\n",
      "Epoch 32/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.1548e-04 - masked_auc: 0.7396 - val_loss: 4.1074e-04 - val_masked_auc: 0.7489 - lr: 2.5000e-04\n",
      "Epoch 33/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.1698e-04 - masked_auc: 0.7389 - val_loss: 4.0972e-04 - val_masked_auc: 0.7496 - lr: 2.5000e-04\n",
      "Epoch 34/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.1589e-04 - masked_auc: 0.7404 - val_loss: 4.1033e-04 - val_masked_auc: 0.7493 - lr: 2.5000e-04\n",
      "Epoch 35/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.1544e-04 - masked_auc: 0.7411 - val_loss: 4.0969e-04 - val_masked_auc: 0.7495 - lr: 2.5000e-04\n",
      "Epoch 36/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.1556e-04 - masked_auc: 0.7412 - val_loss: 4.0986e-04 - val_masked_auc: 0.7486 - lr: 2.5000e-04\n",
      "Epoch 37/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.1461e-04 - masked_auc: 0.7446 - val_loss: 4.1014e-04 - val_masked_auc: 0.7485 - lr: 2.5000e-04\n",
      "Epoch 38/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.1501e-04 - masked_auc: 0.7425 - val_loss: 4.0981e-04 - val_masked_auc: 0.7502 - lr: 2.5000e-04\n",
      "Epoch 39/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.1484e-04 - masked_auc: 0.7413 - val_loss: 4.0981e-04 - val_masked_auc: 0.7495 - lr: 2.5000e-04\n",
      "Epoch 40/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.1483e-04 - masked_auc: 0.7424 - val_loss: 4.1058e-04 - val_masked_auc: 0.7490 - lr: 2.5000e-04\n",
      "Epoch 41/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.1563e-04 - masked_auc: 0.7404 - val_loss: 4.0995e-04 - val_masked_auc: 0.7486 - lr: 2.5000e-04\n",
      "Epoch 42/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.1469e-04 - masked_auc: 0.7428 - val_loss: 4.0972e-04 - val_masked_auc: 0.7488 - lr: 2.5000e-04\n",
      "Epoch 43/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.1584e-04 - masked_auc: 0.7401 - val_loss: 4.1031e-04 - val_masked_auc: 0.7489 - lr: 2.5000e-04\n",
      "Epoch 44/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.1445e-04 - masked_auc: 0.7433 - val_loss: 4.1016e-04 - val_masked_auc: 0.7495 - lr: 1.2500e-04\n",
      "Epoch 45/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.1518e-04 - masked_auc: 0.7424 - val_loss: 4.1019e-04 - val_masked_auc: 0.7488 - lr: 1.2500e-04\n",
      "Epoch 46/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.1477e-04 - masked_auc: 0.7416 - val_loss: 4.1041e-04 - val_masked_auc: 0.7491 - lr: 1.2500e-04\n",
      "Epoch 47/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.1339e-04 - masked_auc: 0.7459 - val_loss: 4.1040e-04 - val_masked_auc: 0.7490 - lr: 1.2500e-04\n",
      "Epoch 48/100\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 4.1432e-04 - masked_auc: 0.7438 - val_loss: 4.1042e-04 - val_masked_auc: 0.7498 - lr: 1.2500e-04\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 4.1644e-04 - masked_auc: 0.7432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Fold 4 - loss: 0.0004164405108895153\n",
      "INFO:root:Fold 4 - masked_auc: 0.7431594729423523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# GPU Configuration\n",
    "def configure_gpu():\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    if physical_devices:\n",
    "        try:\n",
    "            for device in physical_devices:\n",
    "                tf.config.experimental.set_memory_growth(device, True)\n",
    "            tf.config.experimental.set_visible_devices(physical_devices, 'GPU')\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            logging.info(f'{len(physical_devices)} Physical GPUs, {len(logical_gpus)} Logical GPUs')\n",
    "        except RuntimeError as e:\n",
    "            logging.error(f\"GPU configuration error: {e}\")\n",
    "    else:\n",
    "        logging.warning(\"No GPU devices found\")\n",
    "\n",
    "configure_gpu()\n",
    "\n",
    "# Check if TensorFlow is using GPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "missing_value_indicator = -1\n",
    "\n",
    "def check_data(data, name=\"Data\"):\n",
    "    \"\"\"Check if the data contains NaN or infinite values.\"\"\"\n",
    "    if np.any(np.isnan(data)) or np.any(np.isinf(data)):\n",
    "        logging.warning(f\"{name} contains NaN or infinite values.\")\n",
    "    else:\n",
    "        logging.info(f\"{name} is clean.\")\n",
    "\n",
    "# Custom Loss Function to Ignore Missing Values\n",
    "def custom_loss(y_true, y_pred):\n",
    "    mask = tf.not_equal(y_true, missing_value_indicator)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    y_true_masked = tf.multiply(y_true, mask)\n",
    "    y_pred_masked = tf.multiply(y_pred, mask)\n",
    "    loss = tf.keras.losses.binary_crossentropy(y_true_masked, y_pred_masked)\n",
    "    loss = tf.reduce_sum(loss) / tf.reduce_sum(mask)  # Normalize by the number of available targets\n",
    "    return loss\n",
    "\n",
    "# Custom AUC function to ignore missing values\n",
    "class MaskedAUC(tf.keras.metrics.AUC):\n",
    "    def __init__(self, name='masked_auc', **kwargs):\n",
    "        super(MaskedAUC, self).__init__(name=name, **kwargs)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        mask = tf.not_equal(y_true, missing_value_indicator)\n",
    "        mask = tf.cast(mask, dtype=tf.bool)\n",
    "        y_true_masked = tf.boolean_mask(y_true, mask)\n",
    "        y_pred_masked = tf.boolean_mask(y_pred, mask)\n",
    "        super(MaskedAUC, self).update_state(y_true_masked, y_pred_masked, sample_weight)\n",
    "\n",
    "# Build the Neural Network with Regularization and Batch Normalization\n",
    "def build_model(input_dim, output_dim):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(input_dim,)),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(output_dim, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss=custom_loss, metrics=[MaskedAUC()])\n",
    "    return model\n",
    "\n",
    "def load_and_preprocess_data(train_path, test_path, data, assays_list):\n",
    "    train_data = pd.read_csv(train_path)[[\"smiles\"]]\n",
    "    train_data = pd.merge(train_data, data, on=\"smiles\")\n",
    "    \n",
    "    test_data = pd.read_csv(test_path)[[\"smiles\"]]\n",
    "    test_data = pd.merge(test_data, data, on=\"smiles\")\n",
    "    \n",
    "    X_train = train_data[[\"Cells_Number_Object_Number\"]].values\n",
    "    X_test = test_data[[\"Cells_Number_Object_Number\"]].values\n",
    "    \n",
    "    # Normalize features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    y_train = train_data[assays_list].replace(np.nan, missing_value_indicator).values\n",
    "    y_test = test_data[assays_list].replace(np.nan, missing_value_indicator).values\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def train_and_evaluate_model(fold, data, assays_list):\n",
    "    train_path = f\"PUMA/predictions/chemical_cv{fold}/assay_matrix_discrete_train_scaff.csv\"\n",
    "    test_path = f\"PUMA/predictions/chemical_cv{fold}/assay_matrix_discrete_test_scaff.csv\"\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = load_and_preprocess_data(train_path, test_path, data, assays_list)\n",
    "    \n",
    "    # Check data for NaN or infinite values\n",
    "    check_data(X_train, \"X_train\")\n",
    "    check_data(y_train, \"y_train\")\n",
    "    check_data(X_test, \"X_test\")\n",
    "    check_data(y_test, \"y_test\")\n",
    "    \n",
    "    input_dim = X_train.shape[1]\n",
    "    output_dim = y_train.shape[1]\n",
    "    \n",
    "    model = build_model(input_dim, output_dim)\n",
    "\n",
    "    # Create a stratified split for the validation set using multilabel stratification\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    for train_index, val_index in mskf.split(X_train, y_train):\n",
    "        X_train_split, X_val_split = X_train[train_index], X_train[val_index]\n",
    "        y_train_split, y_val_split = y_train[train_index], y_train[val_index]\n",
    "        break  # Only need the first split\n",
    "\n",
    "    # Define early stopping, learning rate scheduler, and model checkpoint\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_masked_auc', patience=10, restore_best_weights=True, mode='max')\n",
    "    lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_masked_auc', factor=0.5, patience=5, mode='max')\n",
    "    model_checkpoint = tf.keras.callbacks.ModelCheckpoint(f'best_model_fold_{fold}.h5', save_best_only=True, monitor='val_masked_auc', mode='max')\n",
    "\n",
    "    # Train the Neural Network\n",
    "    history = model.fit(X_train_split, y_train_split, epochs=100, batch_size=32, validation_data=(X_val_split, y_val_split),\n",
    "                        callbacks=[early_stopping, lr_scheduler, model_checkpoint])\n",
    "\n",
    "    # Evaluate the Model\n",
    "    metrics = model.evaluate(X_test, y_test)\n",
    "    for name, value in zip(model.metrics_names, metrics):\n",
    "        logging.info(f\"Fold {fold} - {name}: {value}\")\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    predictions_df = pd.DataFrame(predictions, columns=assays_list)\n",
    "    predictions_df.to_csv(f\"predictions_fold_{fold}.csv\", index=False)\n",
    "    \n",
    "    y_test_df = pd.DataFrame(y_test, columns=assays_list)\n",
    "    y_test_df.to_csv(f\"y_test_fold_{fold}.csv\", index=False)\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    for fold in range(5):\n",
    "        train_and_evaluate_model(fold, data, assays_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eaf5a9-02a5-483d-a145-8d6de8e0c1a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
